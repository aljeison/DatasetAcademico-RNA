
# ğŸ“ DatasetAcadÃ©mico â€“ RegresiÃ³n LogÃ­stica de AprobaciÃ³n

AplicaciÃ³n web sencilla en **Flask** que genera un **dataset acadÃ©mico sintÃ©tico**, define una variable binaria **Aprobado / No Aprobado** y entrena una **regresiÃ³n logÃ­stica** para clasificar estudiantes segÃºn su desempeÃ±o.

El objetivo es servir como ejemplo prÃ¡ctico para el **Punto 1 (RegresiÃ³n LogÃ­stica)** del taller de Machine Learning.

---

## ğŸ§  Idea del proyecto

Se simulan N estudiantes (por defecto 10.000).  
Cada fila del dataset representa un estudiante, con variables numÃ©ricas que podrÃ­an existir en un sistema acadÃ©mico real.

### Variables de entrada (X)

Todas **numÃ©ricas**:

- `PromedioAcumulado` â€“ promedio histÃ³rico del estudiante (escala 0â€“5).
- `AsistenciaPct` â€“ porcentaje de asistencia a clase (50â€“100 %).
- `HorasEstudioSem` â€“ horas de estudio a la semana (0â€“25).
- `TareasEntregadasPct` â€“ porcentaje de tareas entregadas (30â€“100 %).
- `Parcial1` â€“ nota del primer parcial (0â€“5).
- `Parcial2` â€“ nota del segundo parcial (0â€“5).
- `DificultadMateria` â€“ nivel de dificultad (1â€“5).
- `IntentosReprobados` â€“ nÃºmero de veces que ha reprobado la materia (0â€“2).

### Variables de salida (Y)

- `PromedioFinal` â€“ nota final de la materia (0â€“5), calculada con una **fÃ³rmula fija** que combina parciales, tareas, asistencia y penalizaciones por dificultad e intentos reprobados.
- `Aprobado` â€“ **variable binaria**:
  - `1` si `PromedioFinal â‰¥ 3.0`
  - `0` si `PromedioFinal < 3.0`

La regresiÃ³n logÃ­stica se entrena para predecir `Aprobado` a partir de las variables X.

---

## ğŸ§© Flujo del modelo

1. **GeneraciÃ³n / carga del dataset**
   - Si no existe `dataset_notas.csv`, se genera automÃ¡ticamente con el tamaÃ±o solicitado.
   - Si existe pero estÃ¡ incompleto o con columnas distintas, se vuelve a generar.

2. **PreparaciÃ³n de datos**
   - Se separan:
     - `X` = columnas de entrada (`PromedioAcumulado`, `AsistenciaPct`, â€¦, `IntentosReprobados`)
     - `y` = columna objetivo binaria (`Aprobado`)

3. **Entrenamiento de la regresiÃ³n logÃ­stica**
   - Se divide en **train (80%)** y **test (20%)** con `train_test_split`.
   - Se entrena un modelo `LogisticRegression` de `scikit-learn`.

4. **EvaluaciÃ³n**
   - MÃ©tricas sobre el conjunto de prueba:
     - **Accuracy** (exactitud),
     - **Error rate** (1 âˆ’ accuracy),
     - **PrecisiÃ³n (precision)**,
     - **Recall (exhaustividad)**,
     - **F1-score**.
   - Se construye la **matriz de confusiÃ³n** con:
     - Verdaderos negativos (TN)
     - Falsos positivos (FP)
     - Falsos negativos (FN)
     - Verdaderos positivos (TP)

5. **Interfaz web (Flask)**
   - Permite:
     - Definir el tamaÃ±o del dataset.
     - Forzar la recreaciÃ³n del CSV.
     - Ver un resumen del dataset (filas, columnas, X y Y).
     - Visualizar las mÃ©tricas y la matriz de confusiÃ³n.
     - Ver una **vista previa** de las tablas X e Y.
     - Descargar:
       - `dataset_notas.csv`
       - `resultados.json` con toda la informaciÃ³n del experimento.

---

## ğŸ—‚ï¸ Estructura del proyecto

```text
DatasetAcademico/
â”œâ”€ app.py                  # Backend Flask + generaciÃ³n de dataset + regresiÃ³n logÃ­stica
â”œâ”€ dataset_notas.csv       # Dataset generado (se crea automÃ¡ticamente si no existe)
â”œâ”€ requirements.txt        # Dependencias del proyecto
â”œâ”€ templates/
â”‚   â””â”€ index.html          # Plantilla principal (frontend)
â””â”€ static/
    â”œâ”€ style.css           # Estilos (tema oscuro)
    â””â”€ app.js              # LÃ³gica del lado del cliente (llamadas a /start y render de tablas)
```

---

## ğŸ’» CÃ³mo ejecutar el proyecto localmente

Recomendado usar **Python 3.11**.

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/Drownfe/DatasetAcademico.git
cd DatasetAcademico
```

### 2ï¸âƒ£ Crear y activar entorno virtual (Windows)

```bash
py -3.11 -m venv venv
venv\Scripts\activate
```

En Linux / macOS:

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Instalar dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

Este proyecto utiliza principalmente:

- `Flask`
- `pandas`
- `numpy`
- `scikit-learn`

### 4ï¸âƒ£ Ejecutar la aplicaciÃ³n

```bash
python app.py
```

DeberÃ­as ver algo como:

```text
* Running on http://127.0.0.1:5000
```

Abre el navegador en:

```text
http://127.0.0.1:5000
```

---

## ğŸ§ª Uso de la interfaz

1. **TamaÃ±o del dataset**  
   - Campo numÃ©rico (ej. 5000, 10000, 20000).  
   - Mientras mÃ¡s grande, mÃ¡s ejemplos para entrenar la regresiÃ³n logÃ­stica.

2. **Re-crear dataset**  
   - Si marcas la casilla, se ignora el CSV actual y se genera uno nuevo con el tamaÃ±o indicado.

3. **BotÃ³n â€œEmpezarâ€**  
   - Lanza el pipeline:
     1. GeneraciÃ³n / carga del dataset.
     2. SeparaciÃ³n X / Y.
     3. Entrenamiento de la regresiÃ³n logÃ­stica.
     4. CÃ¡lculo de mÃ©tricas y matriz de confusiÃ³n.
     5. Renderizado del resumen y tablas.

4. **Dataset CSV**  
   - Descarga `dataset_notas.csv` con todas las filas del dataset.

5. **Resultados JSON**  
   - Descarga `resultados.json` con:
     - `dataset_info`
     - `logistic.metrics`
     - `logistic.confusion_matrix`
     - `preview_X` y `preview_Y`

---

## ğŸ“ˆ CÃ³mo interpretar los resultados (para el informe)

- **Accuracy**  
  ProporciÃ³n de predicciones correctas sobre el conjunto de prueba.  
  Ejemplo: `0.93` â†’ el modelo acierta el 93 % de los casos.

- **Error rate**  
  Complemento del accuracy: `1 âˆ’ accuracy`.  
  Ejemplo: `0.07` â†’ el modelo se equivoca en el 7 % de los casos.

- **PrecisiÃ³n**  
  De todos los estudiantes que el modelo predijo como â€œAprobadoâ€, Â¿quÃ© porcentaje realmente aprueba?

- **Recall**  
  De todos los estudiantes que realmente aprueban, Â¿quÃ© porcentaje detecta el modelo?

- **F1-score**  
  Media armÃ³nica entre precisiÃ³n y recall.  
  Ãštil cuando nos interesa equilibrar ambos.

- **Matriz de confusiÃ³n**  

  |                      | Pred. No aprueba (0) | Pred. Aprueba (1) |
  |----------------------|----------------------|-------------------|
  | **Real: No aprueba** | TN                  | FP                |
  | **Real: Aprueba**    | FN                  | TP                |

  - TN: reprobados clasificados correctamente como reprobados.  
  - FP: reprobados clasificados incorrectamente como aprobados.  
  - FN: aprobados clasificados como reprobados.  
  - TP: aprobados clasificados correctamente como aprobados.

Estos valores son los que se suelen reportar en el documento del taller.

---

## ğŸ“š Posibles extensiones (para el compaÃ±ero o versiones futuras)

- Entrenar una **Red Neuronal** utilizando el mismo dataset (para el Punto 2 del taller).
- AÃ±adir curvas ROC / AUC u otras mÃ©tricas.
- Probar con distintos umbrales de aprobaciÃ³n (ej. 2.5, 3.5) y comparar resultados.
- Incluir anÃ¡lisis de importancia de variables a partir de los coeficientes de la regresiÃ³n logÃ­stica.

---

## ğŸ‘¨â€ğŸ« Uso en el taller

Este proyecto estÃ¡ pensado para:

- Mostrar un ejemplo completo de **clasificaciÃ³n binaria con regresiÃ³n logÃ­stica**.
- Trabajar con un **dataset grande y coherente**, aunque sea sintÃ©tico.
- Tener una interfaz clara donde se vean:
  - Entradas X
  - Salidas Y
  - MÃ©tricas
  - Matriz de confusiÃ³n

Se puede usar tanto para la **exposiciÃ³n en clase** como para dejar el repositorio en GitHub como evidencia del trabajo.
